name: Sync to MotherDuck

on:
  schedule:
    # Run 3 times daily: 3 AM, 11 AM, 7 PM UTC
    - cron: '0 3 * * *'
    - cron: '0 11 * * *'
    - cron: '0 19 * * *'
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'Cargo.toml'
      - 'Cargo.lock'
      - '.github/workflows/sync.yml'
  workflow_dispatch:
    inputs:
      full_sync:
        description: 'Full sync (resync all records)'
        type: boolean
        default: false
      refresh_staging:
        description: 'Refresh staging tables before sync'
        type: boolean
        default: true

# Cancel in-progress runs when a new run is triggered
concurrency:
  group: motherduck-sync
  cancel-in-progress: true

env:
  CARGO_TERM_COLOR: always

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Build
        run: cargo build --release

      - name: Upload binary
        uses: actions/upload-artifact@v4
        with:
          name: motherduck-sync-binary
          path: target/release/motherduck-sync
          retention-days: 1

  test:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Run tests
        run: cargo test --all-features

      - name: Check formatting
        run: cargo fmt --check

      - name: Clippy
        run: cargo clippy --all-features -- -D warnings

  sync:
    needs: [build, test]
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Download binary
        uses: actions/download-artifact@v4
        with:
          name: motherduck-sync-binary
          path: .

      - name: Make executable
        run: chmod +x motherduck-sync

      - name: Test connectivity
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          MOTHERDUCK_TOKEN: ${{ secrets.MOTHERDUCK_TOKEN }}
          SYNC_TABLES_CONFIG: ${{ secrets.SYNC_TABLES_CONFIG }}
        run: ./motherduck-sync test

      - name: Refresh staging tables
        if: ${{ inputs.refresh_staging != false }}
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          # Call stored procedure to refresh staging tables
          # The procedure is defined in Supabase migrations (private)
          psql "$DATABASE_URL" -c "CALL refresh_analytics_staging();"

      - name: Run sync
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          MOTHERDUCK_TOKEN: ${{ secrets.MOTHERDUCK_TOKEN }}
          SYNC_TABLES_CONFIG: ${{ secrets.SYNC_TABLES_CONFIG }}
        run: |
          ARGS="sync"
          if [ "${{ inputs.full_sync }}" = "true" ]; then
            ARGS="$ARGS --full"
          fi
          ./motherduck-sync $ARGS --json | tee sync-result.json

      - name: Verify sync
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          MOTHERDUCK_TOKEN: ${{ secrets.MOTHERDUCK_TOKEN }}
          SYNC_TABLES_CONFIG: ${{ secrets.SYNC_TABLES_CONFIG }}
        run: ./motherduck-sync query --counts

      - name: Upload results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sync-result-${{ github.run_id }}
          path: sync-result.json
          retention-days: 30

      - name: Summary
        if: always()
        run: |
          echo "## Sync Results" >> $GITHUB_STEP_SUMMARY
          if [ -f sync-result.json ]; then
            echo '```json' >> $GITHUB_STEP_SUMMARY
            cat sync-result.json >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "No results file found" >> $GITHUB_STEP_SUMMARY
          fi
